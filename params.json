{
  "name": "RubyNEAT",
  "tagline": "Ruby Neural Evolution of Augmenting Topologies (NEAT)",
  "body": "# Introduction to RubyNEAT\r\n\r\n## What is NEAT?\r\nNEAT is an acronym for Neural Evolution of Augmenting Topologies. In short, neural nets that are evolved from a minimal topology, allowing selection to decide on what topologies are most adequate for resolving the problem at hand.\r\n\r\n## What is RubyNEAT?\r\nRubyNEAT is the world's first (and currently only) implementation of the NEAT algorithm in the Ruby programming language. RubyNEAT leverages some of the benefits of Ruby, such as metaprogramming, to implement activation of the Neural Net.\r\n\r\nBasically, the Neural Nets in RubyNEAT manifests themselves in the Phenotypes as functional programs -- of a sort. You may think of it as an application of Genetic Programming techniques to resolving the NEAT algorithm. As such, once fit Critters (neural nets) are found, they may be extracted as pure Ruby code, not needing the RubyNEAT engine for activation.\r\n\r\n## Architecture\r\n\r\nRubyNEAT comprises many interacting modules. While it is not strictly necessary to understand RubyNEAT at this level of detail, it would be beneficial for a number of reasons, especially in understanding how to tweak the parameters to improve performance for your application. \r\n\r\nRubyNEAT comprises the following modules: Controller, Expressor, Evaluator, Evolver, Population, and Critter.\r\n\r\n#### Controller\r\nThe Controller mediates all aspects of RubyNEAT evolution, the various modules involved and their interactions, and also holds the settings the other modules will refer to. \r\n\r\nThe Controller is singular. There can only be one Controller in the RubyNEAT system. All other objects associated with the Controller shall have embedded in them a reference to their controller.\r\n\r\n#### Evolver\r\nThe Evolver module houses the evolving algorithms for RubyNEAT. It evolves the entire Population of Critters.\r\n\r\n#### Expressor\r\nThe Expressor module is responsible for interpreting the Genotype of the Critters and creating their Phenotypes. The default Expressor generates Ruby code and attaches that code to the Phenotype instances of the Critter. \r\n\r\nIt is entirely possible to swap in a different Expressor and generate code for a different target language, or create some other construct. There is no limit to what you could have an Expressor do.\r\n\r\n#### Evaluator\r\nThe Evaluator is a kind of bridge between the inner \"biology\" of the RubyNEAT \"ecosystem\" and the outside world. It has ties to the RubyNEAT DSL where you encode your own fitness functions and data links to some external problem space. It is, in a sense, the \"gateway\".\r\n\r\n#### Population\r\nThe Population is what your intuition tells you. It is a environment that houses a collection of Critters. \r\n\r\n#### Critter\r\nThe Critter is the embodiment of both the genetics for the neural net and also the expression of the same. It contains, in other words, the Genotype and the Phenotype.\r\n\r\nCritters are mated through the Evolver, and have their genes expressed through the Expressor. \r\n\r\n== Installation==\r\n\r\nYou may install RubyNEAT by cloning the repo at GitHub:\r\n[https://github.com/flajann2/rubyneat RubyNEAT Github]\r\n\r\nOr you may get it via a gem\r\n  > gem install rubyneat --pre \r\n\r\n=== Requirements ===\r\nYou will need at least Ruby 2.0.0, though we strongly recommend 2.1.1 or better. We will NOT be supporting 1.9.x, as that is being phased out anyway.\r\n\r\n== Examples ==\r\nClone:\r\n  > git clone git@github.com:flajann2/rubyneat_examples.git\r\n\r\nand cd into the '''rubyneat_examples''' directory. \r\n\r\nType: \r\n  > neat list neaters\r\n\r\nto get a list of neaters. To run one like, say, the XOR test:\r\n  > neat run xor\r\n\r\n== Note Well ==\r\nThe pole-balancing invpend neater is still under development. It will display a window with the cart and pole, but will not balance yet. Just a matter of me finishing up that code. All the others work.\r\n\r\n=== RubyNEAT ===\r\n\r\n* GitHUB\r\n**  [https://github.com/flajann2/rubyneat RubyNEAT GitHub]\r\n\r\n* Ruby GEM\r\n**  > gem install rubyneat --pre\r\n\r\n=== RubyNEAT Examples ===\r\n* Github\r\n** [https://github.com/flajann2/rubyneat_examples Example Neaters on GitHub]\r\n\r\n== RubyNEAT DSL ==\r\n\r\nI will take the '''XOR''' neater and document it. This is not the perfect way to go, but I will get more extensive later.\r\n\r\n=== The XOR Neater Example ===\r\n require 'xor'\r\n include NEAT::DSL\r\n\r\n-The first lines here includes the special XOR library, which is basically:\r\n def xor(*inp)\r\n   inp.map{|n| (n > 0) ? 1 : 0}.reduce {|p, i| p + ((i > 0) ? 1 : 0) } == 1\r\n end\r\n-\r\n\r\n-Basic settings for the '''XOR''', which can handle more than 2 inputs.\r\n XOR_INPUTS = 2\r\n XOR_STATES = 2 ** XOR_INPUTS\r\n MAX_FIT    = XOR_STATES\r\n ALMOST_FIT = XOR_STATES - 0.5\r\n\r\n- The actual definition of the Neater. Here you specify the parameters RubyNEAT\r\nwill use to run the evolution, as well as the CPPN neuron types, the fitness function,\r\netc.\r\n define \"XOR System\" do\r\n\r\n- Inputs defined as name: Neuron, name: Neuron ... hash. In this segment, we\r\ncreate a block to generate the hash since we can have a variable number of\r\ninputs to the XOR. The input names must be unique. Note that a bias neuron\r\nis also supplied, and it is always called :bias.\r\n   inputs {\r\n     cinv = Hash[(1..XOR_INPUTS).map{|i| [(\"i%s\" % i).to_sym, InputNeuron]}]\r\n     cinv[:bias] = BiasNeuron\r\n     cinv\r\n   }\r\n\r\n- Outputs are defined in a similar fashion to the inputs. The names of all the \r\noutput neurons must be unique. Here in this example we only have one output, and\r\nwe use the hyperbolic tan Neuron as the output. There is also a sigmoid Neuron\r\nthat could be used as well, but the input levels would have to be conditioned\r\nto vary from 0 to 1 instead of from -1 to one.\r\n   outputs out: TanhNeuron\r\n\r\n- Hidden neuron specification is optional. \r\nThe names given here are largely meaningless, but but follow the same rules\r\nfor uniqueness. The neurons specified will be selected randomly as the topologies\r\nare augmented.\r\n  hidden tan: TanhNeuron\r\n\r\n==== Settings ====\r\nFor RubyNEAT. Extensive documentation will be provided on a later date\r\nas to the meanings, which closely follow the parameters for Ken Stanley's NEAT\r\nimplementation.\r\n===== General =====\r\n  hash_on_fitness false\r\n  start_population_size 30\r\n  population_size 30\r\n  max_generations 10000\r\n  max_population_history 10\r\n\r\n===== Evolver probabilities and SDs =====\r\n- Perturbations\r\n  mutate_perturb_gene_weights_prob 0.10\r\n  mutate_perturb_gene_weights_sd 0.25\r\n\r\n===== Complete Change of weight =====\r\n  mutate_change_gene_weights_prob 0.10\r\n  mutate_change_gene_weights_sd 1.00\r\n\r\n===== Adding new neurons and genes =====\r\n  mutate_add_neuron_prob 0.05\r\n  mutate_add_gene_prob 0.20\r\n\r\n===== Switching genes on and off =====\r\n  mutate_gene_disable_prob 0.01\r\n  mutate_gene_reenable_prob 0.01\r\n\r\n  interspecies_mate_rate 0.03\r\n  mate_only_prob 0.10 #0.7\r\n\r\n===== Mating =====\r\n  survival_threshold 0.20 # top % allowed to mate in a species.\r\n  survival_mininum_per_species  4 # for small populations, we need SOMETHING to go on.\r\n\r\n===== Fitness costs =====\r\n  fitness_cost_per_neuron 0.00001\r\n  fitness_cost_per_gene   0.00001\r\n\r\n===== Speciation =====\r\n  compatibility_threshold 2.5\r\n  disjoint_coefficient 0.6\r\n  excess_coefficient 0.6\r\n  weight_coefficient 0.2\r\n  max_species 20\r\n  dropoff_age 15\r\n  smallest_species 5\r\n\r\n===== Sequencing =====\r\nThe evaluation function is called repeatedly, and each iteration is given a\r\nmonotonically increasing integer which represents the sequence number. The results\r\nof each run is returned, and those results are evaluated elsewhere in the Neater.\r\n  start_sequence_at 0\r\n  end_sequence_at 2 ** XOR_INPUTS - 1\r\nend\r\n\r\n==== The Evolution Block ====\r\n evolve do\r\n\r\n===== The Query Block ===== \r\nThis query shall return a vector result that will serve\r\nas the inputs to the critter. \r\n   query { |seq|\r\n     # We'll use the seq to create the xor sequences via\r\n     # the least signficant bits.\r\n     condition_boolean_vector (0 ... XOR_INPUTS).map{|i| (seq & (1 << i)) != 0}\r\n   }\r\n\r\n===== The Compare Block =====\r\nCompare the fitness of two critters. We may choose a different ordering here.\r\n  compare {|f1, f2| f2 <=> f1 }\r\n\r\n===== The Cost of Fitness Block =====\r\nHere we integrate the cost with the fitness.\r\n  cost { |fitvec, cost|\r\n    fit = XOR_STATES - fitvec.reduce {|a,r| a+r} - cost\r\n    $log.debug \">>>>>>> fitvec #{fitvec} => #{fit}, cost #{cost}\"\r\n    fit\r\n  }\r\n\r\n===== The Fitness Block =====\r\nThe fitness block is called for each activation and is given the input vector,\r\nthe output vector, and the sequence number given to the query. The results are\r\nevaluated and a fitness scalar is returned.\r\n  fitness { |vin, vout, seq|\r\n    unless vout == :error\r\n      bin = uncondition_boolean_vector vin\r\n      bout = uncondition_boolean_vector vout\r\n      bactual = [xor(*vin)]\r\n      vactual = condition_boolean_vector bactual\r\n      fit = (bout == bactual) ? 0.00 : 1.00\r\n      #simple_fitness_error(vout, vactual.map{|f| f * 0.50 })\r\n      bfit = (bout == bactual) ? 'T' : 'F'\r\n      fit\r\n    else\r\n      $log.debug \"Error on #{vin} [#{seq}]\"\r\n      1.0\r\n    end\r\n  }\r\n\r\n===== The Termination Condition =====\r\nWhen the desired fitness level is reached, you may want to end the\r\nNeater run. If so, provide a block to do just that.\r\n   stop_on_fitness {|fitness, c|\r\n     puts \"*** Generation Run #{c.generation_num}, best is #{fitness[:best]} ***\\n\\n\"\r\n     fitness[:best] >= ALMOST_FIT\r\n   }\r\n end\r\n\r\n==== Report Generating Block ====\r\nThis particular report block just adds something to the log. You could easily\r\nreplace that with a visual update if you like, etc.\r\n report do |rept|\r\n   $log.info \"REPORT #{rept.to_yaml}\"\r\n end\r\n\r\n==== Engine Run Block ====\r\nThe block here is called upon the completion of each generation. The\r\n'c' parameter is the RubyNEAT Controller, the same as given to the stop_on_fitness\r\nblock.\r\n run_engine do |c|\r\n   $log.info \"******** Run of generation %s completed, history count %d ********\" %\r\n         [c.generation_num, c.population_history.size]\r\n end\r\n\r\n=== Releases ===\r\n\r\n== v0.4.0.alpha.4 ==\r\n* First crude cut of a dashboard rubyneat_dashboard\r\n\r\n== 0.3.5.alpha.6 ==\r\n* Command line workflow is a bit cleaner\r\n* Removed neater examples completely and place them in   \r\n  https://github.com/flajann2/rubyneat_examples\r\n* Cleaned up the internal docs a bit\r\n* Uniquely Generated Named Objects (UGNOs) cleaned up to be respectable\r\n\r\n\r\n== 2015-06-08 ==\r\n* Working on the Iterated ES HyperNEAT still, after being side-tracked by having to make a living. Also creating a maze environment for the critters to operate as bots in order to test the new ES HyperNEAT extension.\r\n* rnDSL, as a result of TWEANN Compositions, is undergoing radical changes. All example Neaters will be eventually update to reflect the new syntax.\r\n\r\n== 2014-09-25 ==\r\nHot on the efforts on adding two major features to RubyNEAT:\r\n\r\n* TWEANN Compositions -- you will be able to define composites of TWEANNs on a per critter basis. This should mirror how, say, biological brains composite themselves into regions of speciality. You may specify different selections of neurons for each TWEANN. This is totally experiential, so we'll see if this results in better convergence for some problems.\r\n\r\n* iterated ES HyperNEAT -- one of the compsitions above can be specified as a Hyper TWEANN, and just represent one of the many compositions you may have.\r\n\r\n* The syntax of the Neater DSL will change quite a bit to reflect the new features, and all of the examples will be rewritten to show this.\r\n\r\nDo not confuse the ANN compositions here with CPPNs, which are completely different. By default, all TWEANNs in HyperNEAT are potential CPPNs anyway, as you can specify more than one neuron type.\r\n\r\n\r\n== 2014-08-03 ==\r\nJust released a very crude alpha cut of a dashboard for RubyNEAT. You will have to install it manually, along with rubyneat. The gem is rubyneat_dashboard.\r\n\r\n* I am currently working on a Dashboard for RubyNEAT. It will be a gemmable plugin that will allow you to use the browser as the dashboard. It will have realtime updates and the like, allowing you to monitor the progress of your Neaters, and to view and possibly set parameters, and to see what your Critters look like.\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}